{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Drift Detection on Real-World Sensor Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "In production machine learning systems, models are trained on historical data — but the real world changes over time. **Feature drift** (also called covariate shift) occurs when the statistical distribution of input features changes, causing a model's predictions to silently degrade even when no code has changed.\n",
    "\n",
    "This notebook implements a lightweight drift detection pipeline and applies it to the [UCI Air Quality dataset](https://archive.ics.uci.edu/dataset/360/air+quality): hourly multisensor readings from an Italian city spanning March 2004 to April 2005.\n",
    "\n",
    "**Feature monitored:** `C6H6(GT)` — ground-truth benzene concentration (μg/m³), a feature strongly correlated with CO levels and known to exhibit seasonal variation.\n",
    "\n",
    "**Methods used:**\n",
    "- **Kolmogorov-Smirnov (KS) two-sample test** — a non-parametric test of whether two samples are drawn from the same distribution\n",
    "- **Wasserstein distance (Earth Mover's Distance)** — measures how much \"work\" is needed to transform one distribution into another\n",
    "\n",
    "Both methods operate on a **sliding window** basis, comparing a recent test window against a preceding baseline window at regular intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "The dataset is fetched directly via the `ucimlrepo` package. It contains 9358 hourly observations across 13 sensor columns. The target variable `y` contains CO concentration readings; the features `X` contain the remaining sensor and reference analyser readings.\n",
    "\n",
    "> **Dataset:** Air Quality UCI — [https://archive.ics.uci.edu/dataset/360/air+quality](https://archive.ics.uci.edu/dataset/360/air+quality)  \n",
    "> **Source:** S. De Vito et al., *Sensors and Actuators B: Chemical*, 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "air_quality = fetch_ucirepo(id=360) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = air_quality.data.features \n",
    "y = air_quality.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(air_quality.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(air_quality.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Preprocessing\n",
    "\n",
    "### 3.1 Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Concatenate Date and Time into a Datetime Index\n",
    "\n",
    "The raw dataset stores date and time as separate string columns using `/` as a date separator. These are combined and parsed into a proper `datetime` index to allow time-based indexing and resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X.Date + ' ' + X.Time\n",
    "a = a.transform(lambda x: x.replace('/', '-'))\n",
    "X['Datetime'] = pd.to_datetime(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Set Datetime as Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['Date', 'Time'], inplace=True)\n",
    "X.set_index(['Datetime'], inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Handle Sentinel Missing Values\n",
    "\n",
    "The dataset encodes missing sensor readings as `-200` rather than `NaN`. These are replaced with `NaN` and the affected rows are dropped. This is standard practice for this dataset and documented in the UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = 'C6H6(GT)'\n",
    "X[feature_col] = X[feature_col].replace(-200, np.nan)\n",
    "X.dropna(subset=[feature_col], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "### 4.1 Seasonal Trend in Benzene Concentration\n",
    "\n",
    "Based on the rolling average, C6H6 concentration is higher in winter months compared to summer months. This is consistent with atmospheric chemistry: colder temperatures reduce boundary layer mixing, and higher combustion activity (heating) increases benzene emissions. This seasonal pattern constitutes a genuine, real-world example of **covariate shift** — the input distribution changes over time even though the underlying physical process is stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute concentration mean over each month and assign it to last day of month\n",
    "c = X[feature_col].groupby(pd.Grouper(freq='ME')).mean()[1:-1]\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(X[feature_col].rolling(24*30).mean(), color='red', label='30-day rolling mean')\n",
    "plt.scatter(c.index, c, alpha=0.3, label='concentration mean over each month')\n",
    "plt.plot(c.index, c)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('microg/m^3')\n",
    "plt.title('C6H6 Concentration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distribution Shift: First 3 Months vs Last 3 Months\n",
    "\n",
    "Comparing the early period (March–April 2004) against the late period (January–April 2005) makes the distributional difference concrete. The two histograms show a clear shift in the central tendency and shape of the benzene distribution — exactly the kind of drift a deployed model would encounter silently over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = X[feature_col][(X.index.year==2004) & (X.index.month<=4)]\n",
    "a2 = X[feature_col][(X.index.year==2005) & (X.index.month>=1)]\n",
    "\n",
    "sns.histplot(a1, alpha=0.4, label='first 3 months')\n",
    "sns.histplot(a2, alpha=0.4, label='last 3 months')\n",
    "plt.title('First 3 Vs. Last 3 Months C6H6 Concentration Distribution')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drift Detection Pipeline\n",
    "\n",
    "### 5.1 Parameter Setup\n",
    "\n",
    "The pipeline uses a **sliding window** approach over the ordered time series:\n",
    "\n",
    "| Parameter | Value | Rationale |\n",
    "|---|---|---|\n",
    "| `intervals` | 50 obs | ~2 days of hourly data; granular enough to catch transitions |\n",
    "| `lookback_to_test_size_ratio` | 3 | Baseline window = 3× test window (150 obs ≈ 6 days) — large enough to be statistically stable |\n",
    "| `start_point` | 200 obs | Burn-in period: ensures a full baseline window exists before the first test |\n",
    "| `alpha` (KS test) | 1e-8 | Conservative threshold to minimise false positives given the large sample sizes |\n",
    "\n",
    "At each test point `t`:\n",
    "- **Test window (`dist_2`):** observations in `[t - 50, t)`\n",
    "- **Baseline window (`dist_1`):** observations in `[t - 200, t - 50)` (150 observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = len(X[feature_col])\n",
    "\n",
    "# performing hypothesis testing after every n interval\n",
    "intervals = 50\n",
    "# size compared to interval to consider as population distribution\n",
    "lookback_to_test_size_ratio = 3\n",
    "# index to start peforming hypothesis testing\n",
    "start_point = intervals * (lookback_to_test_size_ratio+1)\n",
    "# considered alpha for comparing against p-value\n",
    "a = 1e-8\n",
    "\n",
    "\n",
    "time_line_tot = X.index\n",
    "time_line_chosen = X[start_point::intervals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Run KS Test and Wasserstein Distance\n",
    "\n",
    "Both metrics are computed in a single loop to avoid redundant window slicing:\n",
    "\n",
    "- **KS two-sample test (`ks_2samp`):** Tests the null hypothesis H₀ that `dist_1` and `dist_2` are drawn from the same continuous distribution. A very small p-value (< α) leads to rejection of H₀ and flags a potential drift event.\n",
    "\n",
    "- **Wasserstein distance:** Measures the minimum \"cost\" of transforming one empirical distribution into the other. Unlike the KS test, it provides a continuous magnitude of shift rather than a binary flag, making it useful for tracking how severe drift is over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_list = []\n",
    "wasserstein_distance_list = pd.DataFrame(index=time_line_chosen.index, data=[np.nan]*len(time_line_chosen))\n",
    "\n",
    "for t in time_line_chosen.index:\n",
    "    current_idx = np.argwhere(X.index == t)[0][0]\n",
    "    dist_1 = X[feature_col].iloc[current_idx - intervals * (1 + lookback_to_test_size_ratio):current_idx - intervals]\n",
    "    dist_2 = X[feature_col].iloc[current_idx - intervals:current_idx]\n",
    "    \n",
    "    # KS test result\n",
    "    result = stats.ks_2samp(dist_1, dist_2)\n",
    "    p_values_list.append(result.pvalue.item())\n",
    "\n",
    "    # Wasserstein distance result\n",
    "    distance = stats.wasserstein_distance(dist_1, dist_2)\n",
    "    wasserstein_distance_list.loc[t] = distance.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results\n",
    "\n",
    "### 6.1 KS Test — H₀ Rejection Points\n",
    "\n",
    "Test points where the p-value falls below `α = 1e-8` are considered drift alerts. These are timestamps where the recent 50-observation window is statistically inconsistent with the preceding 150-observation baseline at a very high confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_low = np.array(p_values_list) < a\n",
    "\n",
    "shift_times = []\n",
    "\n",
    "for k, v in zip(list(time_line_chosen.index), p_value_low):\n",
    "  if v == True:\n",
    "    print(f\"Timeline: {k}\\t H_0 rejected: {v}\")\n",
    "    shift_times.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vertical lines below mark each timestamp where H₀ was rejected. These cluster around the summer trough and the autumn recovery in benzene levels — the two most rapid distributional transitions in the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(X[feature_col].rolling(24*30).mean(), color='red', label='monthly rolling mean')\n",
    "for t in shift_times:\n",
    "    plt.axvline(t, color='skyblue', linestyle='--')\n",
    "\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('μg/m³')\n",
    "plt.title('$H_{0}$ Rejection Points Via KS Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Wasserstein Distance — Distribution of Values\n",
    "\n",
    "Before applying a threshold, it is useful to inspect the distribution of all computed Wasserstein distances. This informs a principled, data-driven choice of threshold rather than an arbitrary hardcoded value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(wasserstein_distance_list, bins=30, legend=False)\n",
    "plt.xlabel('Wasserstein distance')\n",
    "plt.title('Wasserstein distance distribution for C6H6')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Wasserstein Threshold — 99th Percentile\n",
    "\n",
    "The alert threshold is set at the **99th percentile** of all observed Wasserstein distances. This means only the top 1% of window pairs — those with the most extreme distributional separation — are flagged. This is a statistically principled approach: the threshold adapts to the actual scale of variation in the data rather than relying on a domain-specific constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_percentile = 99\n",
    "wasserstein_threshold = np.percentile(wasserstein_distance_list, q=threshold_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Wasserstein Distance Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(wasserstein_distance_list)\n",
    "plt.scatter(wasserstein_distance_list.index, wasserstein_distance_list[0], alpha=0.3)\n",
    "plt.axhline(wasserstein_threshold, color='red', linestyle='--', alpha=0.3, label='99 percentile threshold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.ylabel('Wasserstein distance')\n",
    "plt.xlabel('time')\n",
    "plt.title(f'Wasserstein Distance over Rolling Window of {intervals}')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wasserstein_distance_high = wasserstein_distance_list[wasserstein_distance_list[0] > wasserstein_threshold].index\n",
    "wasserstein_distance_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Wasserstein Drift Alert Points on Time Series\n",
    "\n",
    "The flagged timestamps (those exceeding the 99th percentile threshold) are overlaid on the rolling mean. These align with the same seasonal transitions identified by the KS test, providing **independent corroboration** from a different statistical measure — strengthening confidence that the alerts reflect genuine distributional changes rather than noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(X[feature_col].rolling(24*30).mean(), color='orange', label='monthly rolling mean')\n",
    "for t in wasserstein_distance_high:\n",
    "    plt.axvline(t, color='crimson', linestyle='--')\n",
    "\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('μg/m³')\n",
    "plt.title(f'{threshold_percentile}th Percentile Wasserstein Distance Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "The pipeline successfully detected real distributional drift in hourly benzene sensor data, with both methods independently flagging the same seasonal transition periods.\n",
    "\n",
    "**Method comparison:**\n",
    "\n",
    "| | KS Test | Wasserstein Distance |\n",
    "|---|---|---|\n",
    "| **Output** | p-value (binary flag at threshold α) | Continuous distance score |\n",
    "| **Sensitivity** | Mean + shape changes | Full distribution shape |\n",
    "| **Threshold** | Fixed α = 1e-8 | Data-driven (99th percentile) |\n",
    "| **Strength** | Strong statistical grounding | Magnitude-aware, interpretable |\n",
    "\n",
    "**Key finding:** Both methods converge on the same drift events, corresponding to the spring–summer drop and autumn rise in benzene concentration — changes driven by real seasonal atmospheric dynamics.\n",
    "\n",
    "**Limitations and extensions:**\n",
    "- The current pipeline processes data post-hoc (batch). For online/streaming use, the window buffer would need to be maintained incrementally.\n",
    "- Only a single feature is monitored. A production system would apply this per feature and aggregate drift scores.\n",
    "- The KS test assumes independent observations; autocorrelated time series data (as here) can inflate Type I error rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 0,
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
